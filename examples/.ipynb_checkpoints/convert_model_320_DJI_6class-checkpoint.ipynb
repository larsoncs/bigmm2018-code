{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libs and set up caffe and caffe_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "import os\n",
    "os.chdir('..')\n",
    "caffe_root = './'\n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "voc_net = caffe.Net(caffe_root + 'models/VGGNet/VOC0712/DJI_6classes/deploy.prototxt',\n",
    "                    caffe_root + 'models/VGGNet/VOC0712/DJI_6classes/DJI_6classes__iter_120000.caffemodel',\n",
    "                    caffe.TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Caffe to CPU mode, load the net in the test phase for inference, and configure input preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "# load PASCAL VOC model specs\n",
    "file = open(caffe_root + 'models/VGGNet/VOC0712/DJI_6classes/deploy.prototxt', 'r')\n",
    "voc_netspec = caffe_pb2.NetParameter()\n",
    "text_format.Merge(str(file.read()), voc_netspec)\n",
    "\n",
    "# load PASCAL VOC labels\n",
    "voc_labelmap_file = caffe_root + 'data/VOC0712/labelmap_voc.prototxt'\n",
    "file = open(voc_labelmap_file, 'r')\n",
    "voc_labelmap = caffe_pb2.LabelMap()\n",
    "text_format.Merge(str(file.read()), voc_labelmap)\n",
    "\n",
    "def get_labelname(labelmap, labels):\n",
    "    num_labels = len(labelmap.item)\n",
    "    labelnames = []\n",
    "    if type(labels) is not list:\n",
    "        labels = [labels]\n",
    "    for label in labels:\n",
    "        found = False\n",
    "        for i in xrange(0, num_labels):\n",
    "            if label == labelmap.item[i].label:\n",
    "                found = True\n",
    "                labelnames.append(labelmap.item[i].display_name)\n",
    "                break\n",
    "        assert found == True\n",
    "    return labelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "transformer = caffe.io.Transformer({'data': voc_net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2, 0, 1))\n",
    "transformer.set_mean('data', np.array([104,117,123])) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = caffe.io.load_image('/home/dawn/data/VOCdevkit/VOC2007/JPEGImages/DJI_0001_00230.jpg')\n",
    "transformed_image = transformer.preprocess('data', image)\n",
    "\n",
    "# set net to batch size of 1\n",
    "# coco_net.blobs['data'].reshape(1,3,320,320)\n",
    "voc_net.blobs['data'].reshape(1,3,320,320)\n",
    "\n",
    "# resizes the image to the right size, applies transformation etc. \n",
    "# coco_net.blobs['data'].data[...] = transformed_image\n",
    "voc_net.blobs['data'].data[...] = transformed_image\n",
    "\n",
    "orig_image = transformer.deprocess('data', voc_net.blobs['data'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images are save to : /home/dawn/data/VOCdevkit/VOC2007/test_img/\n",
      "Test images output are save to : /home/dawn/data/VOCdevkit/VOC2007/test_img_output/\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "dataset_dir = '/home/dawn/data/VOCdevkit/VOC2007/'\n",
    "testlist_path = dataset_dir + 'ImageSets/Main/test.txt'\n",
    "\n",
    "test_img_dir = '/home/dawn/data/VOCdevkit/VOC2007/test_img/'\n",
    "test_output_dir = '/home/dawn/data/VOCdevkit/VOC2007/test_img_output/'\n",
    "\n",
    "if not os.path.exists(test_img_dir):\n",
    "    os.mkdir(test_img_dir)\n",
    "    \n",
    "if not os.path.exists(test_output_dir):\n",
    "    os.mkdir(test_output_dir)\n",
    "\n",
    "testlist = open(testlist_path)\n",
    "for eachline in testlist:\n",
    "    imgname = eachline[:-1]+'.jpg'\n",
    "    shutil.copy(dataset_dir+'JPEGImages/'+imgname, test_img_dir+imgname)\n",
    "\n",
    "print('Test images are save to : ' + test_img_dir)\n",
    "\n",
    "print('Test images output are save to : ' + test_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top5 detections using voc model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set net to batch size of 1\n",
    "image_resize = 320\n",
    "voc_net.blobs['data'].reshape(1,3,image_resize,image_resize)\n",
    "\n",
    "import os\n",
    "import os.path                               \n",
    "\n",
    "for parent,dirnames,filenames in os.walk(test_img_dir):      #三个参数：分别返回1.父目录 2.所有文件夹名字（不含路径） 3.所有文件名字\n",
    "    for filename in filenames:\n",
    "\n",
    "        image = caffe.io.load_image(parent+str(filename))\n",
    "        #plt.imshow(image)\n",
    "        transformed_image = transformer.preprocess('data', image)\n",
    "        voc_net.blobs['data'].data[...] = transformed_image\n",
    "        orig_image = transformer.deprocess('data', voc_net.blobs['data'].data)\n",
    "\n",
    "        # Forward pass.\n",
    "        detections = voc_net.forward()['detection_out']\n",
    "\n",
    "        # Parse the outputs.\n",
    "        det_label = detections[0,0,:,1]\n",
    "        det_conf = detections[0,0,:,2]\n",
    "        det_xmin = detections[0,0,:,3]\n",
    "        det_ymin = detections[0,0,:,4]\n",
    "        det_xmax = detections[0,0,:,5]\n",
    "        det_ymax = detections[0,0,:,6]\n",
    "\n",
    "        # Get detections with confidence higher than 0.6.\n",
    "        top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.2]\n",
    "\n",
    "        top_conf = det_conf[top_indices]\n",
    "        top_label_indices = det_label[top_indices].tolist()\n",
    "        top_labels = get_labelname(voc_labelmap, top_label_indices)\n",
    "        top_xmin = det_xmin[top_indices]\n",
    "        top_ymin = det_ymin[top_indices]\n",
    "        top_xmax = det_xmax[top_indices]\n",
    "        top_ymax = det_ymax[top_indices]\n",
    "\n",
    "        colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "        plt.figure(filename)\n",
    "        plt.imshow(orig_image)\n",
    "        currentAxis = plt.gca()\n",
    "\n",
    "        for i in xrange(top_conf.shape[0]):\n",
    "#             xmin = int(round(top_xmin[i] * image.shape[1]))\n",
    "#             ymin = int(round(top_ymin[i] * image.shape[0]))\n",
    "#             xmax = int(round(top_xmax[i] * image.shape[1]))\n",
    "#             ymax = int(round(top_ymax[i] * image.shape[0]))\n",
    "            xmin = int(round(top_xmin[i] * image_resize))\n",
    "            ymin = int(round(top_ymin[i] * image_resize))\n",
    "            xmax = int(round(top_xmax[i] * image_resize))\n",
    "            ymax = int(round(top_ymax[i] * image_resize))\n",
    "            score = top_conf[i]\n",
    "            label = int(top_label_indices[i])\n",
    "            label_name = top_labels[i]\n",
    "            display_txt = '%s: %.2f'%(label_name, score)\n",
    "            coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "            color = colors[label]\n",
    "            currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n",
    "            currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n",
    "        plt.savefig(test_output_dir+str(filename))\n",
    "        \n",
    "        plt.close(filename)\n",
    "        \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
